{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import argparse\n",
    "import time\n",
    "import pymongo\n",
    "from PIL import Image\n",
    "from bson import Binary\n",
    "import random\n",
    "import string \n",
    "import gridfs\n",
    "import os\n",
    "import datetime;\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/?readPreference=primary&appname=MongoDB%20Compass&ssl=false\")\n",
    "mydb = myclient[\"DB\"]\n",
    "mycol = mydb[\"ObjDet\"]\n",
    "\n",
    "def loadFiles():\n",
    "    with open('application.properties') as file:\n",
    "        file_info = dict()\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            infos = line.split('=')\n",
    "            file_info[infos[0].strip()] = infos[1].strip()\n",
    "        return file_info\n",
    "    \n",
    "def load_yolo():\n",
    "    file = loadFiles()\n",
    "    net = cv2.dnn.readNet(file[\"weights\"], file[\"cfg_file\"])\n",
    "    classes = []\n",
    "    with open(file[\"classes_file\"], \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    layers_names = net.getLayerNames()\n",
    "    output_layers = [layers_names[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "    colors = np.random.uniform(0, 255, size=(len(classes)+10, 3))\n",
    "    return net, classes, colors, output_layers , int(file[\"size\"]), int(file[\"finalsize_X\"]),int(file[\"finalsize_Y\"]),int(file[\"slicing_size\"]),int(file[\"offset\"]) \n",
    "\n",
    "def predict_on_img_chip(img,net,size):\n",
    "    h,w,c = img.shape       #h,w,c are the original height width and no. of channels of the original image. By doing this we get back our original image\n",
    "    print(img.shape)\n",
    "    img = cv2.resize(img, (w,h), fx=0.4, fy=0.4)\n",
    "\n",
    "    height, width, channels = img.shape\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (size, size), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Showing informations on the screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.3:\n",
    "                # Object detected\n",
    "                # print(class_id)\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    #indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    #print(indexes)\n",
    "    #print(boxes)\n",
    "    #print(confidences)\n",
    "\n",
    "    prediciton_values = {'boxes':boxes, 'confidences':confidences, 'class_ids':class_ids}\n",
    "    return prediciton_values\n",
    "def imageSizer(img,length,breadth):\n",
    "    leng = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    if(leng>=width):   \n",
    "        result = cv2.resize(img, (int(width*length/leng),length))\n",
    "    else:\n",
    "        result = cv2.resize(img, (breadth,int(leng*breadth/width)))\n",
    "    return result\n",
    "def boxMerger(box,threshold):\n",
    "    temp=[]\n",
    "    i=0\n",
    "    while i<len(box)-1:\n",
    "        mrk=1\n",
    "        j=i+1\n",
    "        while(i<j and j<len(box)):\n",
    "            lp,arr=lap(box[i],box[j])\n",
    "            if(lp):\n",
    "                mrk=0\n",
    "                box[i]=arr\n",
    "                box.pop(j)\n",
    "            else:\n",
    "                j+=1\n",
    "        \n",
    "        if(mrk):\n",
    "            i+=1\n",
    "    return box\n",
    "def lap(arr,arr1):\n",
    "    arrFin=[]\n",
    "    temp=[]\n",
    "    if((arr[0]<=arr1[0] and arr1[0]<=arr[0]+arr[2] and arr[1]<=arr1[1]and arr1[1]<=arr[1]+arr[3])or(arr[0]<=arr1[0] and arr1[0]<=arr[0]+arr[2] and arr1[1]<=arr[1]and arr[1]<=arr1[1]+arr1[3])):\n",
    "        arrFin.append(min(arr[0],arr1[0]))\n",
    "        arrFin.append(min(arr[1],arr1[1]))\n",
    "        arrFin.append(max(arr[2]+arr[0],arr1[2]+arr1[0])-arrFin[0])\n",
    "        arrFin.append(max(arr[1]+arr[3],arr1[1]+arr1[3])-arrFin[1])\n",
    "    temp=arr\n",
    "    arr=arr1\n",
    "    arr1=temp\n",
    "    if(len(arrFin)==0):\n",
    "        if((arr[0]<=arr1[0] and arr1[0]<=arr[0]+arr[2] and arr[1]<=arr1[1]and arr1[1]<=arr[1]+arr[3])or(arr[0]<=arr1[0] and arr1[0]<=arr[0]+arr[2] and arr1[1]<=arr[1]and arr[1]<=arr1[1]+arr1[3])):\n",
    "            arrFin.append(min(arr[0],arr1[0]))\n",
    "            arrFin.append(min(arr[1],arr1[1]))\n",
    "            arrFin.append(max(arr[2]+arr[0],arr1[2]+arr1[0])-arrFin[0])\n",
    "            arrFin.append(max(arr[1]+arr[3],arr1[1]+arr1[3])-arrFin[1])\n",
    "    if(len(arrFin)>0):\n",
    "        return 1,arrFin\n",
    "    else:\n",
    "        return 0,arrFin\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_detect(img_path,net, classes, colors, output_layers,slicing_size,final_size_X,final_size_Y,size,offset):\n",
    "    start_h, start_w = 0, 0\n",
    "    clsBox={0:[],1:[]}\n",
    "    img = cv2.imread(img_path)\n",
    "    orig_img = imageSizer(img,final_size_X,final_size_Y).copy()\n",
    "    img=orig_img.copy()\n",
    "#     print('Image is imported.')\n",
    "    width,height,channels = img.shape\n",
    "\n",
    "#     print(img.shape)\n",
    "    wNo=100*(width-slicing_size)//(offset*slicing_size)\n",
    "    hNo=100*(height-slicing_size)//(offset*slicing_size)\n",
    "    \n",
    "#     print(wNo,hNo)\n",
    "    img = cv2.resize(img, (int(slicing_size*(1+(hNo*offset/100))),int(slicing_size*(1+(wNo*offset/100)))), fx=0.4, fy=0.4)\n",
    "    w_new, h_new, c_new = img.shape\n",
    "#     print(img.shape)\n",
    "\n",
    "  \n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    tiles = []\n",
    "\n",
    "\n",
    "\n",
    "    # Breaking image into chips of size = slicing_size and then doing predictions on them\n",
    "    # All the predictions are stored in boxes, confidences, class_ids, tiles\n",
    "    i=0\n",
    "    noUp=0\n",
    "    j=0\n",
    "    for i in range(0,slicing_size*offset*hNo//100,slicing_size*offset//100):\n",
    "        for j in range(0,slicing_size*offset*wNo//100,slicing_size*offset//100):\n",
    "#             print(str(noUp)+'/'+str(hNo*wNo)) # this is like loading bar\n",
    "            noUp+=1\n",
    "            print(i,i+slicing_size,j,j+slicing_size)\n",
    "            out = img[j:j+slicing_size,i:i+slicing_size,:]\n",
    "            prediction_values = predict_on_img_chip(out,net,size)\n",
    "            print(prediction_values)\n",
    "            chip_boxes = prediction_values['boxes']\n",
    "            chip_confidences = prediction_values['confidences']\n",
    "            chip_class_ids = prediction_values['class_ids']\n",
    "            for ind in range(len(chip_boxes)):\n",
    "                x, y, w, h = chip_boxes[ind]\n",
    "                chip_boxes[ind] = x + i, y + j, w, h\n",
    "                if(chip_confidences[ind]>0.4):\n",
    "                    clsBox[chip_class_ids[ind]].append(chip_boxes[ind])\n",
    "               \n",
    "             \n",
    "           \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "#     indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3) #0.4, 0.3\n",
    "#     print(indexes)\n",
    "\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "\n",
    "    # In the loop we are putting the predicted bounding boxes on the image with proper color\n",
    "    # Red is for Radome and Blue is for MeshAntenna\n",
    "    labls=[]\n",
    "    imgs=[]\n",
    "    imgnw=orig_img.copy()\n",
    "    for i in clsBox.keys():\n",
    "        clsBox[i]=boxMerger(clsBox[i],1)\n",
    "        for j in clsBox[i]:\n",
    "            print(i,j)\n",
    "            x, y, w, h = j\n",
    "            x = int(x/h_new * height)\n",
    "            y = int(y/w_new * width)\n",
    "            w = int(w/h_new * height)\n",
    "            h = int(h/w_new * width)\n",
    "            label = str(classes[i])\n",
    "            color = colors[i]\n",
    "            boxes.append(j)\n",
    "            class_ids.append(i)\n",
    "            labls.append(label)\n",
    "            newimg=imgnw[y:y+h,x:x+w].copy()  \n",
    "            imgs.append(newimg)\n",
    "            cv2.rectangle(orig_img, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(orig_img, label, (x, y-10), font, 2, color, 2)\n",
    "        \n",
    "#     for i in range(len(boxes)):\n",
    "#          if i in indexes:\n",
    "#             x, y, w, h = boxes[i]\n",
    "#             x = int(x/h_new * height)\n",
    "#             y = int(y/w_new * width)\n",
    "#             w = int(w/h_new * height)\n",
    "#             h = int(h/w_new * width)\n",
    "#             label = str(classes[class_ids[i]])\n",
    "#             color = colors[class_ids[i]]\n",
    "#             labls.append(label)\n",
    "#             newimg=imgnw[y:y+h,x:x+w].copy()  \n",
    "#             imgs.append(newimg)\n",
    "#             cv2.rectangle(orig_img, (x, y), (x + w, y + h), color, 2)\n",
    "#             cv2.putText(orig_img, label, (x, y-10), font, 2, color, 2)\n",
    "    return orig_img,imgnw, boxes,class_ids,imgs,labls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net, classes, colors, output_layers, size, final_size_X, final_size_Y, slicing_size, offset = load_yolo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benton (1).jpg\n",
      "Image is imported.\n",
      "(607, 1080, 3)\n",
      "4 8\n",
      "(600, 1000, 3)\n",
      "0/32\n",
      "0 200 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "1/32\n",
      "0 200 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "2/32\n",
      "0 200 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "3/32\n",
      "0 200 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "4/32\n",
      "100 300 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [[121, 29, 15, 17], [144, 38, 14, 19]], 'confidences': [0.848721444606781, 0.5609269142150879], 'class_ids': [1, 1]}\n",
      "5/32\n",
      "100 300 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "6/32\n",
      "100 300 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "7/32\n",
      "100 300 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "8/32\n",
      "200 400 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [[23, 29, 14, 18], [44, 38, 13, 19]], 'confidences': [0.8434667587280273, 0.4270467162132263], 'class_ids': [1, 1]}\n",
      "9/32\n",
      "200 400 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "10/32\n",
      "200 400 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "11/32\n",
      "200 400 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "12/32\n",
      "300 500 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "13/32\n",
      "300 500 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [[139, 139, 31, 24]], 'confidences': [0.6039777994155884], 'class_ids': [1]}\n",
      "14/32\n",
      "300 500 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [[143, 39, 23, 22]], 'confidences': [0.42750611901283264], 'class_ids': [1]}\n",
      "15/32\n",
      "300 500 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "16/32\n",
      "400 600 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "17/32\n",
      "400 600 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [[40, 138, 30, 26], [104, 163, 36, 34], [5, 77, 18, 17]], 'confidences': [0.5506504774093628, 0.9800053834915161, 0.38462501764297485], 'class_ids': [1, 1, 1]}\n",
      "18/32\n",
      "400 600 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [[44, 39, 24, 22], [106, 62, 34, 36]], 'confidences': [0.4596787393093109, 0.9973289370536804], 'class_ids': [1, 1]}\n",
      "19/32\n",
      "400 600 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "20/32\n",
      "500 700 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "21/32\n",
      "500 700 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [[3, 164, 38, 32]], 'confidences': [0.9535378813743591], 'class_ids': [1]}\n",
      "22/32\n",
      "500 700 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [[4, 61, 38, 38], [7, 60, 31, 39]], 'confidences': [0.9782128930091858, 0.4943172335624695], 'class_ids': [1, 1]}\n",
      "23/32\n",
      "500 700 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "24/32\n",
      "600 800 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "25/32\n",
      "600 800 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "26/32\n",
      "600 800 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "27/32\n",
      "600 800 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "28/32\n",
      "700 900 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "29/32\n",
      "700 900 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "30/32\n",
      "700 900 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "31/32\n",
      "700 900 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "()\n",
      "1 [221, 29, 16, 18]\n",
      "1 [244, 38, 14, 19]\n",
      "1 [439, 238, 31, 26]\n",
      "1 [503, 260, 39, 39]\n",
      "./images/Benton (1).jpg done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NANDA KUMAR\\.conda\\envs\\man\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-70a911ece3c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mentries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./images/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    time.sleep(2)\n",
    "    entries = os.listdir('./images/')\n",
    "    if(len(entries)):\n",
    "        time.sleep(5)\n",
    "        for file in entries:\n",
    "            print(file)\n",
    "            img,imgog, boxes,class_ids,imgs,labls = image_detect(\"./images/\"+file, net, classes, colors, output_layers,slicing_size,final_size_X,final_size_Y,size,offset)\n",
    "            box=[]\n",
    "            for i in range(len(boxes)):\n",
    "                box.append({\"dim\":list(boxes[i]),\"class|\":int(class_ids[i])})\n",
    "\n",
    "            ran = ''.join(random.choices(string.ascii_uppercase + string.digits, k = 5))    \n",
    "\n",
    "            ran+=str(mycol.count())\n",
    "\n",
    "            filename = \"img11.jpg\"\n",
    "            cv2.imwrite(filename,imgog)\n",
    "            datafile = open(filename,'rb');\n",
    "            thedata = datafile.read()\n",
    "\n",
    "            fs = gridfs.GridFS(mydb)\n",
    "\n",
    "            fs.put(thedata, filename=ran+\"org.jpg\")\n",
    "\n",
    "            cv2.imwrite(filename,img)\n",
    "            datafile = open(filename,'rb');\n",
    "            thedata = datafile.read()\n",
    "            fs.put(thedata, filename=ran+\"mpl.jpg\")\n",
    "            imgno=0\n",
    "            subimgData=[]\n",
    "            for igs in imgs:\n",
    "                cv2.imwrite(filename,igs)\n",
    "                datafile = open(filename,'rb');\n",
    "                thedata = datafile.read()\n",
    "                fs.put(thedata, filename=ran+\"sub\"+str(imgno)+\".jpg\")\n",
    "                subimgData.append({\"label\":labls[imgno],\"data\":ran+\"sub\"+str(imgno)+\".jpg\"})\n",
    "                imgno+=1\n",
    "\n",
    "            \n",
    "\n",
    "            data={\"timestamp\":datetime.datetime.now(),\"image\":ran+\"org.jpg\",\"ODAC\":ran+\"mpl.jpg\",\"boxes\":box,\"subImagedata\":subimgData}\n",
    "\n",
    "            mycol.insert_one(data)\n",
    "            os.remove(\"./images/\"+file)\n",
    "            print(\"./images/\"+file+ \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image is imported.\n",
      "(720, 1080, 3)\n",
      "5 8\n",
      "(700, 1000, 3)\n",
      "0/40\n",
      "0 200 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "1/40\n",
      "0 200 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [[102, 146, 12, 19]], 'confidences': [0.5574509501457214], 'class_ids': [1]}\n",
      "2/40\n",
      "0 200 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [[102, 46, 12, 19]], 'confidences': [0.4998789131641388], 'class_ids': [1]}\n",
      "3/40\n",
      "0 200 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "4/40\n",
      "0 200 400 600\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "5/40\n",
      "100 300 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "6/40\n",
      "100 300 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "7/40\n",
      "100 300 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "8/40\n",
      "100 300 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "9/40\n",
      "100 300 400 600\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "10/40\n",
      "200 400 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "11/40\n",
      "200 400 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "12/40\n",
      "200 400 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "13/40\n",
      "200 400 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "14/40\n",
      "200 400 400 600\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "15/40\n",
      "300 500 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "16/40\n",
      "300 500 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "17/40\n",
      "300 500 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "18/40\n",
      "300 500 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "19/40\n",
      "300 500 400 600\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "20/40\n",
      "400 600 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "21/40\n",
      "400 600 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "22/40\n",
      "400 600 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "23/40\n",
      "400 600 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "24/40\n",
      "400 600 400 600\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "25/40\n",
      "500 700 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "26/40\n",
      "500 700 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "27/40\n",
      "500 700 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [[135, 193, 11, 6]], 'confidences': [0.7925306558609009], 'class_ids': [1]}\n",
      "28/40\n",
      "500 700 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [[134, 90, 20, 16], [136, 94, 11, 8]], 'confidences': [0.6700417995452881, 0.31897151470184326], 'class_ids': [1, 1]}\n",
      "29/40\n",
      "500 700 400 600\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "30/40\n",
      "600 800 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "31/40\n",
      "600 800 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "32/40\n",
      "600 800 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [[35, 193, 11, 5]], 'confidences': [0.782315731048584], 'class_ids': [1]}\n",
      "33/40\n",
      "600 800 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [[35, 89, 20, 17]], 'confidences': [0.6632007956504822], 'class_ids': [1]}\n",
      "34/40\n",
      "600 800 400 600\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "35/40\n",
      "700 900 0 200\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "36/40\n",
      "700 900 100 300\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "37/40\n",
      "700 900 200 400\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "38/40\n",
      "700 900 300 500\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "39/40\n",
      "700 900 400 600\n",
      "(200, 200, 3)\n",
      "{'boxes': [], 'confidences': [], 'class_ids': []}\n",
      "()\n",
      "1 [102, 246, 12, 19]\n",
      "1 [634, 389, 21, 17]\n"
     ]
    }
   ],
   "source": [
    "img,imgog, boxes,class_ids,imgs,labls = image_detect(\"./img11.jpg\", net, classes, colors, output_layers,slicing_size,final_size_X,final_size_Y,size,offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = 'image'\n",
    "  \n",
    "# Using cv2.imshow() method \n",
    "# Displaying the image \n",
    "cv2.imshow(window_name,imgs[1])\n",
    "  \n",
    "#waits for user to press any key \n",
    "#(this is necessary to avoid Python kernel form  crashing)\n",
    "cv2.waitKey(0) \n",
    "  \n",
    "#closing all open windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object detecter\\Benton (1).jpg\n",
    "C:\\Users\\NANDA KUMAR\\aaFreelancer\\object detecter\\img11.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0a27c22dec37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mentries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./images/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    time.sleep(2)\n",
    "    entries = os.listdir('./images/')\n",
    "    if(len(entries)):\n",
    "        time.sleep(5)\n",
    "        for file in entries:\n",
    "            print(file)\n",
    "            img,imgog, boxes,class_ids,imgs,labls = image_detect(\"./images/\"+file, net, classes, colors, output_layers,slicing_size,final_size_X,final_size_Y)\n",
    "            box=[]\n",
    "            for i in range(len(boxes)):\n",
    "                box.append({\"dim\":list(boxes[i]),\"class\":int(class_ids[i])})\n",
    "\n",
    "            ran = ''.join(random.choices(string.ascii_uppercase + string.digits, k = 5))    \n",
    "\n",
    "            ran+=str(mycol.count())\n",
    "\n",
    "            filename = \"img11.jpg\"\n",
    "            cv2.imwrite(filename,imgog)\n",
    "            datafile = open(filename,'rb');\n",
    "            thedata = datafile.read()\n",
    "\n",
    "            fs = gridfs.GridFS(mydb)\n",
    "\n",
    "            fs.put(thedata, filename=ran+\"org.jpg\")\n",
    "\n",
    "            cv2.imwrite(filename,img)\n",
    "            datafile = open(filename,'rb');\n",
    "            thedata = datafile.read()\n",
    "            fs.put(thedata, filename=ran+\"mpl.jpg\")\n",
    "            imgno=0\n",
    "            subimgData=[]\n",
    "            for igs in imgs:\n",
    "                cv2.imwrite(filename,igs)\n",
    "                datafile = open(filename,'rb');\n",
    "                thedata = datafile.read()\n",
    "                fs.put(thedata, filename=ran+\"sub\"+str(imgno)+\".jpg\")\n",
    "                subimgData.append({\"label\":labls[imgno],\"data\":ran+\"sub\"+str(imgno)+\".jpg\"})\n",
    "                imgno+=1\n",
    "\n",
    "            \n",
    "\n",
    "            data={\"timestamp\":datetime.datetime.now(),\"image\":ran+\"org.jpg\",\"ODAC\":ran+\"mpl.jpg\",\"boxes\":box,\"subImagedata\":subimgData}\n",
    "\n",
    "            mycol.insert_one(data)\n",
    "            os.remove(\"./images/\"+file)\n",
    "            print(\"./images/\"+file+ \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolo_boxes(model, images, net_h, net_w, anchors, obj_thresh, nms_thresh):\n",
    "    image_h, image_w, _ = images[0].shape\n",
    "    nb_images           = len(images)\n",
    "    batch_input         = np.zeros((nb_images, net_h, net_w, 3))\n",
    "\n",
    "    # preprocess the input\n",
    "    for i in range(nb_images):\n",
    "        batch_input[i] = preprocess_input(images[i], net_h, net_w)        \n",
    "\n",
    "    # run the prediction\n",
    "    batch_output = model.predict_on_batch(batch_input)\n",
    "    batch_boxes  = [None]*nb_images\n",
    "\n",
    "    for i in range(nb_images):\n",
    "        yolos = [batch_output[0][i], batch_output[1][i], batch_output[2][i]]\n",
    "        boxes = []\n",
    "\n",
    "        # decode the output of the network\n",
    "        for j in range(len(yolos)):\n",
    "            yolo_anchors = anchors[(2-j)*6:(3-j)*6] # config['model']['anchors']\n",
    "            boxes += decode_netout(yolos[j], yolo_anchors, obj_thresh, net_h, net_w)\n",
    "\n",
    "        # correct the sizes of the bounding boxes\n",
    "        correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\n",
    "\n",
    "        # suppress non-maximal boxes\n",
    "        do_nms(boxes, nms_thresh)        \n",
    "           \n",
    "        batch_boxes[i] = boxes\n",
    "\n",
    "    return batch_boxes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting object_detection\n",
      "  Downloading object_detection-0.0.3-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: lxml in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from object_detection) (4.5.2)\n",
      "Collecting Cython\n",
      "  Downloading Cython-0.29.23-cp36-cp36m-win_amd64.whl (1.6 MB)\n",
      "Collecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from object_detection) (2.1.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from object_detection) (7.1.2)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from object_detection) (3.1.2)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from jupyter->object_detection) (5.3.4)\n",
      "Requirement already satisfied: notebook in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from jupyter->object_detection) (6.1.4)\n",
      "Collecting jupyter-console\n",
      "  Downloading jupyter_console-6.4.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from jupyter->object_detection) (6.0.7)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.1.0-py3-none-any.whl (119 kB)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-7.6.3-py2.py3-none-any.whl (121 kB)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (1.0.8)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (3.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (1.1.0)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Downloading scipy-1.4.1-cp36-cp36m-win_amd64.whl (30.8 MB)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (3.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (1.15.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (1.1.2)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (1.31.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (1.19.5)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (0.35.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorflow->object_detection) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from matplotlib->object_detection) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from matplotlib->object_detection) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from matplotlib->object_detection) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from matplotlib->object_detection) (2.8.1)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from ipykernel->jupyter->object_detection) (7.12.0)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from ipykernel->jupyter->object_detection) (6.0.4)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from ipykernel->jupyter->object_detection) (6.1.7)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from ipykernel->jupyter->object_detection) (4.3.3)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from notebook->jupyter->object_detection) (1.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from notebook->jupyter->object_detection) (19.0.2)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from notebook->jupyter->object_detection) (0.8.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from notebook->jupyter->object_detection) (0.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from notebook->jupyter->object_detection) (2.11.2)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from notebook->jupyter->object_detection) (20.1.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from notebook->jupyter->object_detection) (5.0.7)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from notebook->jupyter->object_detection) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from notebook->jupyter->object_detection) (4.6.3)\n",
      "Requirement already satisfied: pygments in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from jupyter-console->jupyter->object_detection) (2.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from jupyter-console->jupyter->object_detection) (3.0.7)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from nbconvert->jupyter->object_detection) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from nbconvert->jupyter->object_detection) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from nbconvert->jupyter->object_detection) (1.4.2)\n",
      "Requirement already satisfied: bleach in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from nbconvert->jupyter->object_detection) (3.2.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from nbconvert->jupyter->object_detection) (0.6.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from nbconvert->jupyter->object_detection) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from nbconvert->jupyter->object_detection) (0.8.4)\n",
      "Requirement already satisfied: testpath in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from nbconvert->jupyter->object_detection) (0.4.4)\n",
      "Collecting qtpy\n",
      "  Downloading QtPy-1.9.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting widgetsnbextension~=3.5.0\n",
      "  Downloading widgetsnbextension-3.5.1-py2.py3-none-any.whl (2.2 MB)\n",
      "Collecting jupyterlab-widgets>=1.0.0; python_version >= \"3.6\"\n",
      "  Downloading jupyterlab_widgets-1.0.0-py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow->object_detection) (2.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from protobuf>=3.8.0->tensorflow->object_detection) (50.3.0.post20201005)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (0.16.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (1.22.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (2.24.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->object_detection) (0.7.5)\n",
      "Requirement already satisfied: backcall in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->object_detection) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->object_detection) (4.4.2)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->object_detection) (0.4.3)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from ipython>=5.0.0->ipykernel->jupyter->object_detection) (0.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from jinja2->notebook->jupyter->object_detection) (1.1.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from argon2-cffi->notebook->jupyter->object_detection) (1.14.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from nbformat->notebook->jupyter->object_detection) (3.2.0)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from jupyter-core>=4.6.1->notebook->jupyter->object_detection) (227)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->object_detection) (0.2.5)\n",
      "Requirement already satisfied: webencodings in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from bleach->nbconvert->jupyter->object_detection) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from bleach->nbconvert->jupyter->object_detection) (20.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->object_detection) (1.4.1)\n",
      "Requirement already satisfied: async-generator in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->object_detection) (1.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (1.7.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (4.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\" in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (3.6.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (0.2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (3.0.4)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->object_detection) (0.7.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter->object_detection) (2.20)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->jupyter->object_detection) (20.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook->jupyter->object_detection) (0.17.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (0.4.8)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (3.7.4.3)\n",
      "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (1.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (1.5.1)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in c:\\users\\nanda kumar\\.conda\\envs\\man\\lib\\site-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow->object_detection) (4.7.6)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7548 sha256=6a1161995808e11d9711a10f3ff7aea84ab55bf24723a2b14e4f19e5fc471e52\n",
      "  Stored in directory: c:\\users\\nanda kumar\\appdata\\local\\pip\\cache\\wheels\\19\\a7\\b9\\0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
      "Successfully built gast\n",
      "Installing collected packages: Cython, jupyter-console, qtpy, qtconsole, widgetsnbextension, jupyterlab-widgets, ipywidgets, jupyter, contextlib2, object-detection, tensorflow-estimator, scipy, gast, tensorboard\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.3.0\n",
      "    Uninstalling tensorflow-estimator-2.3.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.4\n",
      "    Uninstalling scipy-1.5.4:\n",
      "      Successfully uninstalled scipy-1.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\users\\\\nanda kumar\\\\.conda\\\\envs\\\\man\\\\lib\\\\site-packages\\\\~cipy\\\\.libs\\\\libansari.R6EA3HQP5KZ6TAXU4Y4ZVTRPT7UVA53Z.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model = load_model(\"./backend.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelData ={\n",
    "        \"min_input_size\":       352,\n",
    "        \"max_input_size\":       448,\n",
    "        \"anchors\":              [16,21, 21,45, 25,79, 35,27, 42,54, 62,32, 76,95, 135,184, 238,302],\n",
    "        \"labels\":               [\n",
    "                                \"Airliner\",\n",
    "                                \"Boat\",\n",
    "                                \"Bus\",\n",
    "                                \"Car\",\n",
    "                                \"CharteredAircraft\",\n",
    "                                \"FighterAircraft\",\n",
    "                                \"Helicopter\",\n",
    "                                \"LongVehicle\",\n",
    "                                \"Others\",\n",
    "                                \"PropellerAircraft\",\n",
    "                                \"PushbackTruck\",\n",
    "                                \"StairTruck\",\n",
    "                                \"TrainerAircraft\",\n",
    "                                \"Truck\",\n",
    "                                \"Van\"\n",
    "                                ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_input_size': 352,\n",
       " 'max_input_size': 448,\n",
       " 'anchors': [16,\n",
       "  21,\n",
       "  21,\n",
       "  45,\n",
       "  25,\n",
       "  79,\n",
       "  35,\n",
       "  27,\n",
       "  42,\n",
       "  54,\n",
       "  62,\n",
       "  32,\n",
       "  76,\n",
       "  95,\n",
       "  135,\n",
       "  184,\n",
       "  238,\n",
       "  302],\n",
       " 'labels': ['Airliner',\n",
       "  'Boat',\n",
       "  'Bus',\n",
       "  'Car',\n",
       "  'CharteredAircraft',\n",
       "  'FighterAircraft',\n",
       "  'Helicopter',\n",
       "  'LongVehicle',\n",
       "  'Others',\n",
       "  'PropellerAircraft',\n",
       "  'PushbackTruck',\n",
       "  'StairTruck',\n",
       "  'TrainerAircraft',\n",
       "  'Truck',\n",
       "  'Van']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "def pyramid(image, scale=1.5, minSize=(30, 30)):\n",
    "\t# yield the original image\n",
    "\tyield image\n",
    "\t# keep looping over the pyramid\n",
    "\twhile True:\n",
    "\t\t# compute the new dimensions of the image and resize it\n",
    "\t\tw = int(image.shape[1] / scale)\n",
    "\t\timage = imutils.resize(image, width=w)\n",
    "\t\t# if the resized image does not meet the supplied minimum\n",
    "\t\t# size, then stop constructing the pyramid\n",
    "\t\tif image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "\t\t\tbreak\n",
    "\t\t# yield the next image in the pyramid\n",
    "\t\tyield image\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "\t# slide a window across the image\n",
    "\tfor y in range(0, image.shape[0], stepSize):\n",
    "\t\tfor x in range(0, image.shape[1], stepSize):\n",
    "\t\t\t# yield the current window\n",
    "\t\t\tyield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from pyimagesearch.helpers import pyramid\n",
    "from pyimagesearch.helpers import sliding_window\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True, help=\"Path to the image\")\n",
    "args = vars(ap.parse_args())\n",
    "# load the image and define the window width and height\n",
    "image = cv2.imread(args[\"image\"])\n",
    "(winW, winH) = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the image pyramid\n",
    "for resized in pyramid(image, scale=1.5):\n",
    "\t# loop over the sliding window for each layer of the pyramid\n",
    "\tfor (x, y, window) in sliding_window(resized, stepSize=32, windowSize=(winW, winH)):\n",
    "\t\t# if the window does not meet our desired window size, ignore it\n",
    "\t\tif window.shape[0] != winH or window.shape[1] != winW:\n",
    "\t\t\tcontinue\n",
    "\t\t# THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A\n",
    "\t\t# MACHINE LEARNING CLASSIFIER TO CLASSIFY THE CONTENTS OF THE\n",
    "\t\t# WINDOW\n",
    "\t\t# since we do not have a classifier, we'll just draw the window\n",
    "\t\tclone = resized.copy()\n",
    "\t\tcv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "\t\tcv2.imshow(\"Window\", clone)\n",
    "\t\tcv2.waitKey(1)\n",
    "\t\ttime.sleep(0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxMerger(box,threshold):\n",
    "    temp=[]\n",
    "    i=0\n",
    "    while i<len(box)-1:\n",
    "        mrk=1\n",
    "        j=i+1\n",
    "        while(i<j and j<len(box)):\n",
    "            lp,arr=lap(box[i],box[j])\n",
    "            if(lp):\n",
    "                mrk=0\n",
    "                box[i]=arr\n",
    "                box.pop(j)\n",
    "            else:\n",
    "                j+=1\n",
    "        \n",
    "        if(mrk):\n",
    "            i+=1\n",
    "    return box\n",
    "def lap(arr,arr1):\n",
    "    arrFin=[]\n",
    "    temp=[]\n",
    "    if((arr[0]<=arr1[0] and arr1[0]<=arr[0]+arr[2] and arr[1]<=arr1[1]and arr1[1]<=arr[1]+arr[3])or(arr[0]<=arr1[0] and arr1[0]<=arr[0]+arr[2] and arr1[1]<=arr[1]and arr[1]<=arr1[1]+arr1[3])):\n",
    "        arrFin.append(min(arr[0],arr1[0]))\n",
    "        arrFin.append(min(arr[1],arr1[1]))\n",
    "        arrFin.append(max(arr[2]+arr[0],arr1[2]+arr1[0])-arrFin[0])\n",
    "        arrFin.append(max(arr[1]+arr[3],arr1[1]+arr1[3])-arrFin[1])\n",
    "    temp=arr\n",
    "    arr=arr1\n",
    "    arr1=temp\n",
    "    if(len(arrFin)==0):\n",
    "        if((arr[0]<=arr1[0] and arr1[0]<=arr[0]+arr[2] and arr[1]<=arr1[1]and arr1[1]<=arr[1]+arr[3])or(arr[0]<=arr1[0] and arr1[0]<=arr[0]+arr[2] and arr1[1]<=arr[1]and arr[1]<=arr1[1]+arr1[3])):\n",
    "            arrFin.append(min(arr[0],arr1[0]))\n",
    "            arrFin.append(min(arr[1],arr1[1]))\n",
    "            arrFin.append(max(arr[2]+arr[0],arr1[2]+arr1[0])-arrFin[0])\n",
    "            arrFin.append(max(arr[1]+arr[3],arr1[1]+arr1[3])-arrFin[1])\n",
    "    if(len(arrFin)>0):\n",
    "        return 1,arrFin\n",
    "    else:\n",
    "        return 0,arrFin\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 23, 77, 103], [142, 34, 233, 33]]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxMerger([[12,23,23,34],[12,34,23,33],[16,60,55,66],[54,44,34,34],[45,26,44,34],[142,34,233,33]],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, [10, 10, 20, 20])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lap([15,15,15,15],[10,10,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageBoxer(arr,img):\n",
    "    for i in arr:\n",
    "        cv2.rectangle(img, (i[0],i[1]), (i[0]+i[2], i[1] + i[3]), colors[0], 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img = np.zeros([500,500],dtype=np.uint8)\n",
    "img.fill(233) # or img[:] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "nko=imageBoxer([[12,23,23,34],[12,34,23,33],[16,60,55,66],[54,44,34,34],[45,26,44,34],[142,34,233,33]],img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = 'image'\n",
    "  \n",
    "# Using cv2.imshow() method \n",
    "# Displaying the image \n",
    "cv2.imshow(window_name,nko)\n",
    "  \n",
    "#waits for user to press any key \n",
    "#(this is necessary to avoid Python kernel form crashing)\n",
    "cv2.waitKey(0) \n",
    "  \n",
    "#closing all open windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.uniform(0, 255, size=(len(classes)+10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "nko1=imageBoxer([[12, 23, 77, 103], [-2, 39, 10, 17]],img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = 'image'\n",
    "  \n",
    "# Using cv2.imshow() method \n",
    "# Displaying the image \n",
    "cv2.imshow(window_name,nko1)\n",
    "  \n",
    "#waits for user to press any key \n",
    "#(this is necessary to avoid Python kernel form crashing)\n",
    "cv2.waitKey(0) \n",
    "  \n",
    "#closing all open windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1000-200)*100//(50*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
